"""
Dev.to Collector - Recopila art√≠culos de Dev.to

Dev.to tiene una API p√∫blica GRATIS sin l√≠mites y sin autenticaci√≥n.
Excelente fuente de tutoriales y noticias de desarrollo.

API Docs: https://developers.forem.com/api
"""

import requests
from pathlib import Path
from datetime import datetime
from typing import List, Dict


class DevToCollector:
    """Recolector de art√≠culos desde Dev.to API."""
    
    BASE_URL = "https://dev.to/api"
    
    def __init__(self):
        """Inicializa el recolector de Dev.to."""
        pass
    
    def collect(
        self,
        tag: str = None,
        top: int = None,
        per_page: int = 30,
        min_reactions: int = 10
    ) -> List[Dict]:
        """
        Recopila art√≠culos de Dev.to.
        
        Args:
            tag: Filtrar por tag (python, javascript, react, etc.)
            top: Filtrar por top (n√∫mero de d√≠as: 7, 30, etc.)
            per_page: N√∫mero de art√≠culos por p√°gina (max 1000)
            min_reactions: M√≠nimo de reacciones (likes)
            
        Returns:
            Lista de art√≠culos recopilados
        """
        print(f"üì° Recopilando desde Dev.to (tag: {tag or 'all'})...")
        
        try:
            articles = self._fetch_articles(tag, top, per_page, min_reactions)
            print(f"  ‚úÖ Dev.to: {len(articles)} art√≠culos")
            return articles
        except Exception as e:
            print(f"  ‚ùå Error en Dev.to: {str(e)}")
            return []
    
    def _fetch_articles(
        self,
        tag: str,
        top: int,
        per_page: int,
        min_reactions: int
    ) -> List[Dict]:
        """
        Obtiene art√≠culos de Dev.to API.
        
        Args:
            tag: Tag para filtrar
            top: Top days
            per_page: Art√≠culos por p√°gina
            min_reactions: Reacciones m√≠nimas
            
        Returns:
            Lista de art√≠culos
        """
        url = f"{self.BASE_URL}/articles"
        
        params = {
            'per_page': min(per_page, 1000)
        }
        
        if tag:
            params['tag'] = tag
        
        if top:
            params['top'] = top
        
        response = requests.get(url, params=params, timeout=10)
        
        if response.status_code != 200:
            raise Exception(f"API error: {response.status_code}")
        
        articles_data = response.json()
        
        articles = []
        
        for article in articles_data:
            # Filtrar por reacciones
            reactions = article.get('public_reactions_count', 0)
            if reactions < min_reactions:
                continue
            
            # Parsear fecha
            published = None
            if article.get('published_at'):
                try:
                    published = datetime.fromisoformat(
                        article['published_at'].replace('Z', '+00:00')
                    )
                except:
                    published = None
            
            # Extraer informaci√≥n relevante
            article_item = {
                'title': article.get('title', ''),
                'link': article.get('url', ''),
                'summary': article.get('description', ''),
                'published': published.isoformat() if published else None,
                'source': 'Dev.to',
                'author': article.get('user', {}).get('name', ''),
                'author_username': article.get('user', {}).get('username', ''),
                'reactions': reactions,
                'comments': article.get('comments_count', 0),
                'tags': article.get('tag_list', []),
                'category': 'dev',
                'collected_at': datetime.now().isoformat(),
                'collector': 'devto',
                'cover_image': article.get('cover_image', ''),
                'reading_time': article.get('reading_time_minutes', 0)
            }
            
            articles.append(article_item)
        
        return articles
    
    def collect_multiple_tags(
        self,
        tags: List[str] = None,
        per_page_per_tag: int = 15,
        min_reactions: int = 10
    ) -> List[Dict]:
        """
        Recopila art√≠culos de m√∫ltiples tags.
        
        Args:
            tags: Lista de tags
            per_page_per_tag: Art√≠culos por tag
            min_reactions: Reacciones m√≠nimas
            
        Returns:
            Lista de todos los art√≠culos
        """
        if tags is None:
            tags = [
                'python',
                'javascript',
                'react',
                'webdev',
                'ai',
                'machinelearning',
                'devops',
                'opensource'
            ]
        
        all_articles = []
        
        for tag in tags:
            try:
                articles = self.collect(
                    tag=tag,
                    per_page=per_page_per_tag,
                    min_reactions=min_reactions
                )
                all_articles.extend(articles)
            except Exception as e:
                print(f"‚ùå Error en tag '{tag}': {str(e)}")
        
        return all_articles
    
    def collect_top_this_week(
        self,
        per_page: int = 30,
        min_reactions: int = 50
    ) -> List[Dict]:
        """
        Recopila los art√≠culos top de esta semana.
        
        Args:
            per_page: N√∫mero de art√≠culos
            min_reactions: Reacciones m√≠nimas
            
        Returns:
            Lista de art√≠culos top
        """
        print("üì° Recopilando top articles de esta semana desde Dev.to...")
        
        return self.collect(
            top=7,  # Top de los √∫ltimos 7 d√≠as
            per_page=per_page,
            min_reactions=min_reactions
        )
    
    def save_to_file(self, articles: List[Dict], output_path: str = "data/devto.json"):
        """
        Guarda los art√≠culos recopilados en un archivo JSON.
        
        Args:
            articles: Lista de art√≠culos a guardar
            output_path: Ruta del archivo de salida
        """
        import json
        
        output_file = Path(output_path)
        output_file.parent.mkdir(exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(articles, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ Art√≠culos de Dev.to guardados en: {output_path}")


# Ejemplo de uso
if __name__ == "__main__":
    # Crear el recolector
    collector = DevToCollector()
    
    # Recopilar art√≠culos recientes sin filtro de reactions
    articles = collector.collect(tag='python', per_page=30, min_reactions=0)
    
    # O recopilar top de la semana
    # articles = collector.collect_top_this_week(per_page=30, min_reactions=50)
    
    # O recopilar de m√∫ltiples tags
    # articles = collector.collect_multiple_tags(
    #     tags=['python', 'javascript', 'ai', 'react'],
    #     per_page_per_tag=10
    # )
    
    # Guardar en archivo
    if articles:
        collector.save_to_file(articles)
        
        # Mostrar los primeros 5 art√≠culos
        print("\nüì∞ Primeros 5 art√≠culos:")
        for i, article in enumerate(articles[:5], 1):
            print(f"\n{i}. {article['title']}")
            print(f"   ‚ù§Ô∏è  {article['reactions']} reactions | üí¨ {article['comments']} comments")
            print(f"   üë§ {article['author']} (@{article['author_username']})")
            print(f"   üè∑Ô∏è  Tags: {', '.join(article['tags'][:3])}")
            print(f"   üìö {article['reading_time']} min read")
            print(f"   üîó {article['link']}")
    else:
        print("\n‚ö†Ô∏è  No se recopilaron art√≠culos.")
